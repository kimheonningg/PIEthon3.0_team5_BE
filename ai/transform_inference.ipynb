{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "IDetect.fuse\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# import pickle\n",
    "# from models.experimental import attempt_load  # YOLOv7 모델 로더\n",
    "\n",
    "# # 1. 모델 로드 (YOLOv7)\n",
    "# weights_path = 'runs/train/rcs-yolo/weights/best.pt'\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model = attempt_load(weights_path, map_location=device)\n",
    "# model.eval()\n",
    "\n",
    "# # 2. Pickle로 저장\n",
    "# with open('./brainMRI_model_weights.pkl', 'wb') as f:\n",
    "#     pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils \n",
    "def non_max_suppression(prediction, conf_thres=0.25, iou_thres=0.45, classes=None, agnostic=False, multi_label=False,\n",
    "                        labels=()):\n",
    "    \"\"\"Runs Non-Maximum Suppression (NMS) on inference results\n",
    "\n",
    "    Returns:\n",
    "         list of detections, on (n,6) tensor per image [xyxy, conf, cls]\n",
    "    \"\"\"\n",
    "\n",
    "    nc = prediction.shape[2] - 5  # number of classes\n",
    "    xc = prediction[..., 4] > conf_thres  # candidates\n",
    "\n",
    "    # Settings\n",
    "    min_wh, max_wh = 2, 4096  # (pixels) minimum and maximum box width and height\n",
    "    max_det = 300  # maximum number of detections per image\n",
    "    max_nms = 30000  # maximum number of boxes into torchvision.ops.nms()\n",
    "    time_limit = 10.0  # seconds to quit after\n",
    "    redundant = True  # require redundant detections\n",
    "    multi_label &= nc > 1  # multiple labels per box (adds 0.5ms/img)\n",
    "    merge = False  # use merge-NMS\n",
    "\n",
    "    t = time.time()\n",
    "    output = [torch.zeros((0, 6), device=prediction.device)] * prediction.shape[0]\n",
    "    for xi, x in enumerate(prediction):  # image index, image inference\n",
    "        # Apply constraints\n",
    "        # x[((x[..., 2:4] < min_wh) | (x[..., 2:4] > max_wh)).any(1), 4] = 0  # width-height\n",
    "        x = x[xc[xi]]  # confidence\n",
    "\n",
    "        # Cat apriori labels if autolabelling\n",
    "        if labels and len(labels[xi]):\n",
    "            l = labels[xi]\n",
    "            v = torch.zeros((len(l), nc + 5), device=x.device)\n",
    "            v[:, :4] = l[:, 1:5]  # box\n",
    "            v[:, 4] = 1.0  # conf\n",
    "            v[range(len(l)), l[:, 0].long() + 5] = 1.0  # cls\n",
    "            x = torch.cat((x, v), 0)\n",
    "\n",
    "        # If none remain process next image\n",
    "        if not x.shape[0]:\n",
    "            continue\n",
    "\n",
    "        # Compute conf\n",
    "        if nc == 1:\n",
    "            x[:, 5:] = x[:, 4:5] # for models with one class, cls_loss is 0 and cls_conf is always 0.5,\n",
    "                                 # so there is no need to multiplicate.\n",
    "        else:\n",
    "            x[:, 5:] *= x[:, 4:5]  # conf = obj_conf * cls_conf\n",
    "\n",
    "        # Box (center x, center y, width, height) to (x1, y1, x2, y2)\n",
    "        box = xywh2xyxy(x[:, :4])\n",
    "\n",
    "        # Detections matrix nx6 (xyxy, conf, cls)\n",
    "        if multi_label:\n",
    "            i, j = (x[:, 5:] > conf_thres).nonzero(as_tuple=False).T\n",
    "            x = torch.cat((box[i], x[i, j + 5, None], j[:, None].float()), 1)\n",
    "        else:  # best class only\n",
    "            conf, j = x[:, 5:].max(1, keepdim=True)\n",
    "            x = torch.cat((box, conf, j.float()), 1)[conf.view(-1) > conf_thres]\n",
    "\n",
    "        # Filter by class\n",
    "        if classes is not None:\n",
    "            x = x[(x[:, 5:6] == torch.tensor(classes, device=x.device)).any(1)]\n",
    "\n",
    "        # Apply finite constraint\n",
    "        # if not torch.isfinite(x).all():\n",
    "        #     x = x[torch.isfinite(x).all(1)]\n",
    "\n",
    "        # Check shape\n",
    "        n = x.shape[0]  # number of boxes\n",
    "        if not n:  # no boxes\n",
    "            continue\n",
    "        elif n > max_nms:  # excess boxes\n",
    "            x = x[x[:, 4].argsort(descending=True)[:max_nms]]  # sort by confidence\n",
    "\n",
    "        # Batched NMS\n",
    "        c = x[:, 5:6] * (0 if agnostic else max_wh)  # classes\n",
    "        boxes, scores = x[:, :4] + c, x[:, 4]  # boxes (offset by class), scores\n",
    "        i = torchvision.ops.nms(boxes, scores, iou_thres)  # NMS\n",
    "        if i.shape[0] > max_det:  # limit detections\n",
    "            i = i[:max_det]\n",
    "        if merge and (1 < n < 3E3):  # Merge NMS (boxes merged using weighted mean)\n",
    "            # update boxes as boxes(i,4) = weights(i,n) * boxes(n,4)\n",
    "            iou = box_iou(boxes[i], boxes) > iou_thres  # iou matrix\n",
    "            weights = iou * scores[None]  # box weights\n",
    "            x[i, :4] = torch.mm(weights, x[:, :4]).float() / weights.sum(1, keepdim=True)  # merged boxes\n",
    "            if redundant:\n",
    "                i = i[iou.sum(1) > 1]  # require redundancy\n",
    "\n",
    "        output[xi] = x[i]\n",
    "        if (time.time() - t) > time_limit:\n",
    "            print(f'WARNING: NMS time limit {time_limit}s exceeded')\n",
    "            break  # time limit exceeded\n",
    "\n",
    "    return output\n",
    "\n",
    "def scale_coords(img1_shape, coords, img0_shape, ratio_pad=None):\n",
    "    # Rescale coords (xyxy) from img1_shape to img0_shape\n",
    "    if ratio_pad is None:  # calculate from img0_shape\n",
    "        gain = min(img1_shape[0] / img0_shape[0], img1_shape[1] / img0_shape[1])  # gain  = old / new\n",
    "        pad = (img1_shape[1] - img0_shape[1] * gain) / 2, (img1_shape[0] - img0_shape[0] * gain) / 2  # wh padding\n",
    "    else:\n",
    "        gain = ratio_pad[0][0]\n",
    "        pad = ratio_pad[1]\n",
    "\n",
    "    coords[:, [0, 2]] -= pad[0]  # x padding\n",
    "    coords[:, [1, 3]] -= pad[1]  # y padding\n",
    "    coords[:, :4] /= gain\n",
    "    clip_coords(coords, img0_shape)\n",
    "    return coords\n",
    "\n",
    "def letterbox(img, new_shape=(640, 640), color=(114, 114, 114), auto=True, scaleFill=False, scaleup=True, stride=32):\n",
    "    # Resize and pad image while meeting stride-multiple constraints\n",
    "    shape = img.shape[:2]  # current shape [height, width]\n",
    "    if isinstance(new_shape, int):\n",
    "        new_shape = (new_shape, new_shape)\n",
    "\n",
    "    # Scale ratio (new / old)\n",
    "    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\n",
    "    if not scaleup:  # only scale down, do not scale up (for better test mAP)\n",
    "        r = min(r, 1.0)\n",
    "\n",
    "    # Compute padding\n",
    "    ratio = r, r  # width, height ratios\n",
    "    new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))\n",
    "    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # wh padding\n",
    "    if auto:  # minimum rectangle\n",
    "        dw, dh = np.mod(dw, stride), np.mod(dh, stride)  # wh padding\n",
    "    elif scaleFill:  # stretch\n",
    "        dw, dh = 0.0, 0.0\n",
    "        new_unpad = (new_shape[1], new_shape[0])\n",
    "        ratio = new_shape[1] / shape[1], new_shape[0] / shape[0]  # width, height ratios\n",
    "\n",
    "    dw /= 2  # divide padding into 2 sides\n",
    "    dh /= 2\n",
    "\n",
    "    if shape[::-1] != new_unpad:  # resize\n",
    "        img = cv2.resize(img, new_unpad, interpolation=cv2.INTER_LINEAR)\n",
    "    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))\n",
    "    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))\n",
    "    img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  # add border\n",
    "    return img, ratio, (dw, dh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brain MRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.84932, device='cuda:0') [tensor(41., device='cuda:0'), tensor(57., device='cuda:0'), tensor(164., device='cuda:0'), tensor(206., device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 1. 모델 불러오기\n",
    "with open('./brainMRI_model_weights.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "model.eval()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# 2. 이미지 로드 및 전처리\n",
    "img_path = './dataset-Br35H/valdata/y500.jpg'\n",
    "img0 = cv2.imread(img_path)  # BGR\n",
    "img = letterbox(img0, new_shape=640)[0]\n",
    "img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR->RGB->CHW\n",
    "img = np.ascontiguousarray(img)\n",
    "img = torch.from_numpy(img).float().to(device) / 255.0\n",
    "img = img.unsqueeze(0)  # batch dimension\n",
    "\n",
    "# 3. Inference\n",
    "with torch.no_grad():\n",
    "    pred = model(img, augment=False)[0]\n",
    "    pred = non_max_suppression(pred, conf_thres=0.25, iou_thres=0.45)\n",
    "\n",
    "# 4. 결과 출력\n",
    "for det in pred:\n",
    "    if len(det):\n",
    "        det[:, :4] = scale_coords(img.shape[2:], det[:, :4], img0.shape).round()\n",
    "        for *xyxy, conf, cls in det:\n",
    "            print(int(cls), conf, xyxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biomedparse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
